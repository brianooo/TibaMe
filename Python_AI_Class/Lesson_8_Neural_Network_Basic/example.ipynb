{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\Anaconda3\\envs\\python_37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\brian\\Anaconda3\\envs\\python_37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\brian\\Anaconda3\\envs\\python_37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\brian\\Anaconda3\\envs\\python_37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\brian\\Anaconda3\\envs\\python_37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\brian\\Anaconda3\\envs\\python_37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\brian\\Anaconda3\\envs\\python_37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 29\n",
      "Trainable params: 29\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\brian\\Anaconda3\\envs\\python_37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.6871 - accuracy: 0.7500\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6869 - accuracy: 0.7500\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 768us/step - loss: 0.6868 - accuracy: 0.7500\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 521us/step - loss: 0.6867 - accuracy: 0.7500\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 278us/step - loss: 0.6866 - accuracy: 0.7500\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6865 - accuracy: 0.7500\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 300us/step - loss: 0.6863 - accuracy: 0.7500\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.6862 - accuracy: 0.7500\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 494us/step - loss: 0.6861 - accuracy: 0.7500\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 466us/step - loss: 0.6860 - accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6859 - accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6858 - accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 261us/step - loss: 0.6856 - accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 349us/step - loss: 0.6855 - accuracy: 0.7500\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 243us/step - loss: 0.6854 - accuracy: 0.7500\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 253us/step - loss: 0.6853 - accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 320us/step - loss: 0.6852 - accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.6851 - accuracy: 0.7500\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.6850 - accuracy: 0.7500\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 437us/step - loss: 0.6849 - accuracy: 0.7500\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.6847 - accuracy: 0.7500\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 234us/step - loss: 0.6846 - accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 251us/step - loss: 0.6845 - accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 255us/step - loss: 0.6844 - accuracy: 0.7500\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6843 - accuracy: 0.7500\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6842 - accuracy: 0.7500\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.6841 - accuracy: 0.7500\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 513us/step - loss: 0.6840 - accuracy: 0.7500\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 255us/step - loss: 0.6839 - accuracy: 0.7500\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 228us/step - loss: 0.6837 - accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 238us/step - loss: 0.6836 - accuracy: 0.7500\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 506us/step - loss: 0.6835 - accuracy: 0.7500\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 466us/step - loss: 0.6834 - accuracy: 0.7500\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.6833 - accuracy: 0.7500\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 491us/step - loss: 0.6832 - accuracy: 0.7500\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 519us/step - loss: 0.6831 - accuracy: 0.7500\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.6830 - accuracy: 0.7500\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6829 - accuracy: 0.7500\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6828 - accuracy: 0.7500\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6826 - accuracy: 0.7500\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6825 - accuracy: 0.7500\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.6824 - accuracy: 0.7500\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 364us/step - loss: 0.6823 - accuracy: 0.7500\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 304us/step - loss: 0.6822 - accuracy: 0.7500\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6821 - accuracy: 0.7500\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.6820 - accuracy: 0.7500\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6819 - accuracy: 0.7500\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 226us/step - loss: 0.6818 - accuracy: 0.7500\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6816 - accuracy: 0.7500\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.6815 - accuracy: 0.7500\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6814 - accuracy: 0.7500\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 304us/step - loss: 0.6813 - accuracy: 0.7500\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 629us/step - loss: 0.6812 - accuracy: 0.7500\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 466us/step - loss: 0.6811 - accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6810 - accuracy: 0.7500\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.6808 - accuracy: 0.7500\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 558us/step - loss: 0.6807 - accuracy: 0.7500\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6806 - accuracy: 0.7500\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6805 - accuracy: 0.7500\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6805 - accuracy: 0.7500\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6802 - accuracy: 0.7500\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6801 - accuracy: 0.7500\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6800 - accuracy: 0.7500\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6799 - accuracy: 0.7500\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 245us/step - loss: 0.6798 - accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 156us/step - loss: 0.6797 - accuracy: 0.7500\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6795 - accuracy: 0.7500\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 261us/step - loss: 0.6794 - accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6793 - accuracy: 0.7500\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.6792 - accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 350us/step - loss: 0.6790 - accuracy: 0.7500\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6789 - accuracy: 0.7500\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.6788 - accuracy: 0.7500\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6787 - accuracy: 0.7500\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6785 - accuracy: 0.7500\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6784 - accuracy: 0.7500\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 252us/step - loss: 0.6783 - accuracy: 0.7500\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6781 - accuracy: 0.7500\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.6780 - accuracy: 0.7500\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6779 - accuracy: 0.7500\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6777 - accuracy: 0.7500\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6776 - accuracy: 0.7500\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6774 - accuracy: 0.7500\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6773 - accuracy: 0.7500\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6771 - accuracy: 0.7500\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6770 - accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 274us/step - loss: 0.6768 - accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 495us/step - loss: 0.6767 - accuracy: 0.7500\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6765 - accuracy: 0.7500\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 219us/step - loss: 0.6764 - accuracy: 0.7500\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 255us/step - loss: 0.6763 - accuracy: 0.7500\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 471us/step - loss: 0.6761 - accuracy: 0.7500\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 475us/step - loss: 0.6759 - accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6758 - accuracy: 0.7500\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 538us/step - loss: 0.6756 - accuracy: 0.7500\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 253us/step - loss: 0.6754 - accuracy: 0.7500\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 456us/step - loss: 0.6753 - accuracy: 0.7500\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6751 - accuracy: 0.7500\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.6749 - accuracy: 0.7500\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6748 - accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "#preparing data for Exclusive OR (XOR)\n",
    "\n",
    "attributes = [\n",
    "    #x1, x2\n",
    "    [0 ,0]\n",
    "  , [0, 1]\n",
    "  , [1, 0]\n",
    "  , [1, 1]\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    #is_0, is_1 -> only a column can be 1 in labels variable\n",
    "    [1, 0] \n",
    "  , [0, 1]\n",
    "  , [0, 1]\n",
    "  , [1, 0]\n",
    "]\n",
    "\n",
    "#transforming attributes and labels matrixes to numpy\n",
    "data = np.array(attributes, 'int64')\n",
    "target = np.array(labels, 'int64')\n",
    "\n",
    "\n",
    "#creating model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "#  input layer to 1st hidden layer\n",
    "model.add(Dense(units=3 , input_shape=(2,))) #num of features in input layer\n",
    "\n",
    "# Dense default setting:\n",
    "# kernel_initializer='glorot_uniform', bias_initializer='zeros'\n",
    "# common kernel_initializer: 'glorot_uniform'/\n",
    "\n",
    "model.add(Activation('relu')) #activation function from input layer to 1st hidden layer\n",
    "# common activation: 'relu'/'sigmoid'/'tanh'/'LeakyReLU'\n",
    "\n",
    "#  1st hidden layer to 2end hidden layer\n",
    "model.add(Dense(units=3))\n",
    "model.add(Activation('relu')) #activation function from 1st hidden layer to 2end hidden layer\n",
    "\n",
    "\n",
    "#  2end hidden layer to output layer\n",
    "model.add(Dense(units=2)) #num of classes in output layer\n",
    "model.add(Activation('softmax')) #activation function from 2end hidden layer to output layer\n",
    "\n",
    "# summary model\n",
    "model.summary()\n",
    "\n",
    "#compile\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# different setting on compile\n",
    "# loss='mean_squared_error'/'categorical_crossentropy'/'binary_crossentropy'\n",
    "# optimizer='sgd'/'adam'/'rmsprop'\n",
    "# metrics='accuracy'/'mse'\n",
    "\n",
    "#training\n",
    "score = model.fit(data, target, epochs=100)\n",
    "#verbose: 0, 1 或 2。日志显示模式。 0 = 安静模式, 1 = 进度条, 2 = 每轮一行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function:  \n",
    "binary_crossentropy (2 classes)  \n",
    "categorical_crossentropy (>2 classes)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "MNIST is a computer vision dataset. It consists of black and white images from zero to nine. Each image is 28 * 28 and have been flatten to 784 dimension vector. Also, it includes labels for each image, telling us which digit it is.\n",
    "\n",
    "![Alt text](./images/dnn_implement/Selection_017.png)\n",
    "![Alt text](./images/dnn_implement/Selection_018.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Dataset - training and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 7s 1us/step\n",
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "print(train_images[0])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[0])\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 59,850\n",
      "Trainable params: 59,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 6s 116us/step - loss: 0.2882 - accuracy: 0.9160 - val_loss: 0.1394 - val_accuracy: 0.9588\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 5s 110us/step - loss: 0.1278 - accuracy: 0.9616 - val_loss: 0.1238 - val_accuracy: 0.9626\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 5s 107us/step - loss: 0.0907 - accuracy: 0.9721 - val_loss: 0.1169 - val_accuracy: 0.9647\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 5s 110us/step - loss: 0.0707 - accuracy: 0.9779 - val_loss: 0.0992 - val_accuracy: 0.9688\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 5s 111us/step - loss: 0.0562 - accuracy: 0.9819 - val_loss: 0.1122 - val_accuracy: 0.9671\n"
     ]
    }
   ],
   "source": [
    "# Normalize the images.\n",
    "train_images = (train_images / 255)\n",
    "test_images = (test_images / 255)\n",
    "\n",
    "# Flatten the images.\n",
    "train_images = train_images.reshape((-1, 784))\n",
    "test_images = test_images.reshape((-1, 784))\n",
    "\n",
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(64, activation='relu', input_shape=(784,)),\n",
    "  Dense(128, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Summary model\n",
    "model.summary()\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "train_history = model.fit(\n",
    "  x=train_images,\n",
    "  y=to_categorical(train_labels),\n",
    "  validation_split=0.2,\n",
    "  epochs=5,\n",
    "  batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history.history['loss'])  \n",
    "plt.plot(train_history.history['val_loss'])  \n",
    "plt.title('Train History')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.legend(['loss', 'val_loss'], loc='upper left')  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 38us/step\n",
      "test accuracy is 0.9692000150680542\n",
      "[7 2 1 0 4]\n",
      "[7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "test_loss, test_acc = model.evaluate(test_images, to_categorical(test_labels))\n",
    "\n",
    "print('test accuracy is {}'.format(test_acc))\n",
    "\n",
    "# Predict on the first 5 test images.\n",
    "predictions = model.predict(test_images[:5])\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(test_labels[:5]) # [7, 2, 1, 0, 4]'''\n",
    "\n",
    "# Save the model to disk.\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Dataset - load model and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 37us/step\n",
      "test accuracy is 0.9692000150680542\n",
      "[7 2 1 0 4]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "(_, _), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "x_test = test_images.reshape((10000, 28 * 28)) \n",
    "x_test = x_test.astype('float32') / 255      \n",
    "y_test  = to_categorical(test_labels)\n",
    "\n",
    "\n",
    "model = load_model('model.h5')  \n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test) \n",
    "print('test accuracy is {}'.format(test_acc))\n",
    "\n",
    "# Predict on the first 5 test images.\n",
    "predictions = model.predict(x_test[:5])\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(y_test[:5]) # [7, 2, 1, 0, 4]'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 337,674\n",
      "Trainable params: 337,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\Anaconda3\\envs\\python_37\\lib\\site-packages\\ipykernel_launcher.py:55: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.2966 - accuracy: 0.9078 - val_loss: 0.1297 - val_accuracy: 0.9613\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.1340 - accuracy: 0.9599 - val_loss: 0.0959 - val_accuracy: 0.9706\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.1028 - accuracy: 0.9691 - val_loss: 0.0895 - val_accuracy: 0.9726\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.0871 - accuracy: 0.9732 - val_loss: 0.0766 - val_accuracy: 0.9793\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0760 - accuracy: 0.9778 - val_loss: 0.0842 - val_accuracy: 0.9782\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.0681 - accuracy: 0.9796 - val_loss: 0.0708 - val_accuracy: 0.9804\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0622 - accuracy: 0.9815 - val_loss: 0.0782 - val_accuracy: 0.9796\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0579 - accuracy: 0.9824 - val_loss: 0.0704 - val_accuracy: 0.9815\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.0527 - accuracy: 0.9847 - val_loss: 0.0743 - val_accuracy: 0.9814\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0510 - accuracy: 0.9850 - val_loss: 0.0737 - val_accuracy: 0.9828\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.0484 - accuracy: 0.9859 - val_loss: 0.0738 - val_accuracy: 0.9826\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0438 - accuracy: 0.9870 - val_loss: 0.0756 - val_accuracy: 0.9837\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.0406 - accuracy: 0.9880 - val_loss: 0.0832 - val_accuracy: 0.9838\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.0424 - accuracy: 0.9875 - val_loss: 0.0869 - val_accuracy: 0.9810\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0411 - accuracy: 0.9882 - val_loss: 0.0870 - val_accuracy: 0.9838\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0374 - accuracy: 0.9899 - val_loss: 0.0906 - val_accuracy: 0.9818\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.0348 - accuracy: 0.9897 - val_loss: 0.0967 - val_accuracy: 0.9831\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0356 - accuracy: 0.9903 - val_loss: 0.0862 - val_accuracy: 0.9840\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.0347 - accuracy: 0.9901 - val_loss: 0.0918 - val_accuracy: 0.9833\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0368 - accuracy: 0.9904 - val_loss: 0.0929 - val_accuracy: 0.9834\n",
      "10000/10000 [==============================] - 1s 62us/step\n",
      "Test score: 0.09289488336427103\n",
      "Test accuracy: 0.9833999872207642\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 20\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "# add dropout\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "# add dropout\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('Train History')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.legend(['loss', 'val_loss'], loc='upper left')  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 4us/step\n",
      "[  1.23247   0.        8.14      0.        0.538     6.142    91.7\n",
      "   3.9769    4.      307.       21.      396.9      18.72   ]\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.2\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(8, activation='relu', input_shape=[X_train.shape[1]]))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/100\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 591.8293 - mae: 22.6116 - val_loss: 654.3442 - val_mae: 23.9187\n",
      "Epoch 2/100\n",
      "323/323 [==============================] - 0s 90us/step - loss: 580.2683 - mae: 22.3572 - val_loss: 644.7691 - val_mae: 23.7223\n",
      "Epoch 3/100\n",
      "323/323 [==============================] - 0s 74us/step - loss: 570.9208 - mae: 22.1559 - val_loss: 635.9067 - val_mae: 23.5414\n",
      "Epoch 4/100\n",
      "323/323 [==============================] - 0s 84us/step - loss: 562.1471 - mae: 21.9668 - val_loss: 626.8533 - val_mae: 23.3566\n",
      "Epoch 5/100\n",
      "323/323 [==============================] - 0s 80us/step - loss: 553.2818 - mae: 21.7748 - val_loss: 617.2855 - val_mae: 23.1623\n",
      "Epoch 6/100\n",
      "323/323 [==============================] - 0s 88us/step - loss: 543.9507 - mae: 21.5784 - val_loss: 607.3671 - val_mae: 22.9594\n",
      "Epoch 7/100\n",
      "323/323 [==============================] - 0s 79us/step - loss: 534.2318 - mae: 21.3706 - val_loss: 597.9489 - val_mae: 22.7637\n",
      "Epoch 8/100\n",
      "323/323 [==============================] - 0s 88us/step - loss: 524.6688 - mae: 21.1662 - val_loss: 586.7110 - val_mae: 22.5317\n",
      "Epoch 9/100\n",
      "323/323 [==============================] - 0s 87us/step - loss: 513.6946 - mae: 20.9288 - val_loss: 574.8627 - val_mae: 22.2844\n",
      "Epoch 10/100\n",
      "323/323 [==============================] - 0s 92us/step - loss: 502.0994 - mae: 20.6795 - val_loss: 563.1210 - val_mae: 22.0353\n",
      "Epoch 11/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 490.2500 - mae: 20.4238 - val_loss: 549.9376 - val_mae: 21.7555\n",
      "Epoch 12/100\n",
      "323/323 [==============================] - 0s 92us/step - loss: 477.2616 - mae: 20.1405 - val_loss: 535.6163 - val_mae: 21.4479\n",
      "Epoch 13/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 463.5483 - mae: 19.8348 - val_loss: 519.7606 - val_mae: 21.1026\n",
      "Epoch 14/100\n",
      "323/323 [==============================] - 0s 96us/step - loss: 448.9826 - mae: 19.5054 - val_loss: 506.9644 - val_mae: 20.8165\n",
      "Epoch 15/100\n",
      "323/323 [==============================] - 0s 95us/step - loss: 435.8568 - mae: 19.2006 - val_loss: 491.7601 - val_mae: 20.4712\n",
      "Epoch 16/100\n",
      "323/323 [==============================] - 0s 100us/step - loss: 420.8718 - mae: 18.8465 - val_loss: 475.7145 - val_mae: 20.0969\n",
      "Epoch 17/100\n",
      "323/323 [==============================] - 0s 78us/step - loss: 405.1582 - mae: 18.4692 - val_loss: 458.3762 - val_mae: 19.6808\n",
      "Epoch 18/100\n",
      "323/323 [==============================] - 0s 98us/step - loss: 388.3909 - mae: 18.0549 - val_loss: 439.4980 - val_mae: 19.2171\n",
      "Epoch 19/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 370.8097 - mae: 17.5997 - val_loss: 422.8938 - val_mae: 18.7917\n",
      "Epoch 20/100\n",
      "323/323 [==============================] - 0s 91us/step - loss: 354.2277 - mae: 17.1606 - val_loss: 403.6101 - val_mae: 18.2802\n",
      "Epoch 21/100\n",
      "323/323 [==============================] - 0s 92us/step - loss: 335.8904 - mae: 16.6502 - val_loss: 383.3919 - val_mae: 17.7287\n",
      "Epoch 22/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 317.5429 - mae: 16.1202 - val_loss: 366.2052 - val_mae: 17.2225\n",
      "Epoch 23/100\n",
      "323/323 [==============================] - 0s 97us/step - loss: 300.4604 - mae: 15.5928 - val_loss: 346.0127 - val_mae: 16.6027\n",
      "Epoch 24/100\n",
      "323/323 [==============================] - 0s 98us/step - loss: 282.1092 - mae: 14.9935 - val_loss: 328.0932 - val_mae: 16.0283\n",
      "Epoch 25/100\n",
      "323/323 [==============================] - 0s 99us/step - loss: 264.8789 - mae: 14.4105 - val_loss: 308.4800 - val_mae: 15.3524\n",
      "Epoch 26/100\n",
      "323/323 [==============================] - 0s 94us/step - loss: 247.2727 - mae: 13.7458 - val_loss: 289.8503 - val_mae: 14.6680\n",
      "Epoch 27/100\n",
      "323/323 [==============================] - 0s 92us/step - loss: 230.1005 - mae: 13.0942 - val_loss: 271.4433 - val_mae: 13.9521\n",
      "Epoch 28/100\n",
      "323/323 [==============================] - 0s 96us/step - loss: 213.7262 - mae: 12.4599 - val_loss: 253.9640 - val_mae: 13.2697\n",
      "Epoch 29/100\n",
      "323/323 [==============================] - 0s 94us/step - loss: 198.8269 - mae: 11.8254 - val_loss: 236.7366 - val_mae: 12.5921\n",
      "Epoch 30/100\n",
      "323/323 [==============================] - 0s 92us/step - loss: 184.1869 - mae: 11.2196 - val_loss: 221.7300 - val_mae: 11.9963\n",
      "Epoch 31/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 171.4162 - mae: 10.6462 - val_loss: 207.8676 - val_mae: 11.4595\n",
      "Epoch 32/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 159.7232 - mae: 10.1199 - val_loss: 195.5591 - val_mae: 10.9929\n",
      "Epoch 33/100\n",
      "323/323 [==============================] - 0s 95us/step - loss: 149.7805 - mae: 9.6244 - val_loss: 183.5296 - val_mae: 10.5328\n",
      "Epoch 34/100\n",
      "323/323 [==============================] - 0s 91us/step - loss: 140.5981 - mae: 9.1864 - val_loss: 173.4135 - val_mae: 10.2077\n",
      "Epoch 35/100\n",
      "323/323 [==============================] - 0s 90us/step - loss: 133.1879 - mae: 8.8199 - val_loss: 167.1434 - val_mae: 9.9816\n",
      "Epoch 36/100\n",
      "323/323 [==============================] - 0s 91us/step - loss: 127.6186 - mae: 8.5344 - val_loss: 160.1801 - val_mae: 9.7340\n",
      "Epoch 37/100\n",
      "323/323 [==============================] - 0s 96us/step - loss: 121.9876 - mae: 8.2857 - val_loss: 152.7517 - val_mae: 9.4545\n",
      "Epoch 38/100\n",
      "323/323 [==============================] - 0s 96us/step - loss: 116.5117 - mae: 8.0150 - val_loss: 145.9616 - val_mae: 9.1994\n",
      "Epoch 39/100\n",
      "323/323 [==============================] - 0s 97us/step - loss: 111.3676 - mae: 7.7534 - val_loss: 140.8692 - val_mae: 8.9906\n",
      "Epoch 40/100\n",
      "323/323 [==============================] - 0s 99us/step - loss: 107.0003 - mae: 7.5543 - val_loss: 135.4287 - val_mae: 8.7719\n",
      "Epoch 41/100\n",
      "323/323 [==============================] - 0s 97us/step - loss: 102.6126 - mae: 7.3550 - val_loss: 130.2051 - val_mae: 8.5462\n",
      "Epoch 42/100\n",
      "323/323 [==============================] - 0s 91us/step - loss: 98.3368 - mae: 7.1669 - val_loss: 124.3406 - val_mae: 8.3085\n",
      "Epoch 43/100\n",
      "323/323 [==============================] - 0s 94us/step - loss: 93.8352 - mae: 6.9599 - val_loss: 118.5680 - val_mae: 8.0718\n",
      "Epoch 44/100\n",
      "323/323 [==============================] - 0s 92us/step - loss: 89.6064 - mae: 6.7717 - val_loss: 113.6876 - val_mae: 7.8474\n",
      "Epoch 45/100\n",
      "323/323 [==============================] - 0s 97us/step - loss: 86.0604 - mae: 6.6083 - val_loss: 108.7218 - val_mae: 7.6478\n",
      "Epoch 46/100\n",
      "323/323 [==============================] - 0s 99us/step - loss: 82.5547 - mae: 6.4602 - val_loss: 104.4715 - val_mae: 7.4373\n",
      "Epoch 47/100\n",
      "323/323 [==============================] - 0s 99us/step - loss: 79.2255 - mae: 6.2939 - val_loss: 99.7177 - val_mae: 7.2245\n",
      "Epoch 48/100\n",
      "323/323 [==============================] - 0s 104us/step - loss: 75.9984 - mae: 6.1566 - val_loss: 96.2219 - val_mae: 7.0513\n",
      "Epoch 49/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 73.4149 - mae: 6.0122 - val_loss: 92.6223 - val_mae: 6.8761\n",
      "Epoch 50/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 70.9327 - mae: 5.8777 - val_loss: 88.4520 - val_mae: 6.6521\n",
      "Epoch 51/100\n",
      "323/323 [==============================] - 0s 89us/step - loss: 68.2754 - mae: 5.7462 - val_loss: 85.4735 - val_mae: 6.5045\n",
      "Epoch 52/100\n",
      "323/323 [==============================] - 0s 87us/step - loss: 66.1562 - mae: 5.6263 - val_loss: 82.1540 - val_mae: 6.3267\n",
      "Epoch 53/100\n",
      "323/323 [==============================] - 0s 94us/step - loss: 63.9454 - mae: 5.5049 - val_loss: 79.3996 - val_mae: 6.1840\n",
      "Epoch 54/100\n",
      "323/323 [==============================] - 0s 102us/step - loss: 61.9566 - mae: 5.3879 - val_loss: 77.0880 - val_mae: 6.0477\n",
      "Epoch 55/100\n",
      "323/323 [==============================] - 0s 96us/step - loss: 59.9885 - mae: 5.2675 - val_loss: 74.2824 - val_mae: 5.9105\n",
      "Epoch 56/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 58.1428 - mae: 5.1725 - val_loss: 71.6968 - val_mae: 5.7798\n",
      "Epoch 57/100\n",
      "323/323 [==============================] - 0s 96us/step - loss: 56.3367 - mae: 5.0579 - val_loss: 69.0941 - val_mae: 5.6838\n",
      "Epoch 58/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 54.9822 - mae: 4.9909 - val_loss: 66.9700 - val_mae: 5.5682\n",
      "Epoch 59/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 53.3839 - mae: 4.8814 - val_loss: 64.5777 - val_mae: 5.4564\n",
      "Epoch 60/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 51.9338 - mae: 4.7998 - val_loss: 62.7049 - val_mae: 5.3749\n",
      "Epoch 61/100\n",
      "323/323 [==============================] - 0s 90us/step - loss: 50.5678 - mae: 4.7189 - val_loss: 60.9130 - val_mae: 5.2937\n",
      "Epoch 62/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 49.2494 - mae: 4.6355 - val_loss: 59.1054 - val_mae: 5.2229\n",
      "Epoch 63/100\n",
      "323/323 [==============================] - 0s 95us/step - loss: 47.9616 - mae: 4.5627 - val_loss: 57.7327 - val_mae: 5.1565\n",
      "Epoch 64/100\n",
      "323/323 [==============================] - 0s 92us/step - loss: 46.8491 - mae: 4.4941 - val_loss: 56.0779 - val_mae: 5.0739\n",
      "Epoch 65/100\n",
      "323/323 [==============================] - 0s 95us/step - loss: 45.6420 - mae: 4.4123 - val_loss: 54.5346 - val_mae: 4.9874\n",
      "Epoch 66/100\n",
      "323/323 [==============================] - 0s 104us/step - loss: 44.5255 - mae: 4.3368 - val_loss: 52.7829 - val_mae: 4.8994\n",
      "Epoch 67/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 43.4480 - mae: 4.2743 - val_loss: 51.2191 - val_mae: 4.8268\n",
      "Epoch 68/100\n",
      "323/323 [==============================] - 0s 90us/step - loss: 42.3398 - mae: 4.2122 - val_loss: 50.6978 - val_mae: 4.7986\n",
      "Epoch 69/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 41.5821 - mae: 4.1695 - val_loss: 49.1125 - val_mae: 4.7127\n",
      "Epoch 70/100\n",
      "323/323 [==============================] - 0s 100us/step - loss: 40.6895 - mae: 4.1117 - val_loss: 48.6210 - val_mae: 4.6880\n",
      "Epoch 71/100\n",
      "323/323 [==============================] - 0s 105us/step - loss: 39.7776 - mae: 4.0560 - val_loss: 47.3736 - val_mae: 4.6189\n",
      "Epoch 72/100\n",
      "323/323 [==============================] - 0s 90us/step - loss: 38.9279 - mae: 4.0041 - val_loss: 46.8484 - val_mae: 4.5924\n",
      "Epoch 73/100\n",
      "323/323 [==============================] - 0s 90us/step - loss: 38.3357 - mae: 3.9608 - val_loss: 45.9414 - val_mae: 4.5600\n",
      "Epoch 74/100\n",
      "323/323 [==============================] - 0s 90us/step - loss: 37.5911 - mae: 3.9143 - val_loss: 45.0332 - val_mae: 4.5183\n",
      "Epoch 75/100\n",
      "323/323 [==============================] - 0s 89us/step - loss: 36.8471 - mae: 3.8719 - val_loss: 44.2305 - val_mae: 4.4852\n",
      "Epoch 76/100\n",
      "323/323 [==============================] - 0s 92us/step - loss: 36.0135 - mae: 3.8201 - val_loss: 43.4111 - val_mae: 4.4446\n",
      "Epoch 77/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 35.2271 - mae: 3.7832 - val_loss: 42.4816 - val_mae: 4.4011\n",
      "Epoch 78/100\n",
      "323/323 [==============================] - 0s 108us/step - loss: 34.3319 - mae: 3.7220 - val_loss: 41.5625 - val_mae: 4.3655\n",
      "Epoch 79/100\n",
      "323/323 [==============================] - 0s 96us/step - loss: 33.5794 - mae: 3.6806 - val_loss: 40.6378 - val_mae: 4.3192\n",
      "Epoch 80/100\n",
      "323/323 [==============================] - 0s 96us/step - loss: 32.8619 - mae: 3.6453 - val_loss: 39.6707 - val_mae: 4.2748\n",
      "Epoch 81/100\n",
      "323/323 [==============================] - 0s 87us/step - loss: 32.0870 - mae: 3.6115 - val_loss: 39.0479 - val_mae: 4.2447\n",
      "Epoch 82/100\n",
      "323/323 [==============================] - 0s 99us/step - loss: 31.5247 - mae: 3.6023 - val_loss: 38.0999 - val_mae: 4.2008\n",
      "Epoch 83/100\n",
      "323/323 [==============================] - 0s 89us/step - loss: 30.8751 - mae: 3.5640 - val_loss: 36.8965 - val_mae: 4.1486\n",
      "Epoch 84/100\n",
      "323/323 [==============================] - 0s 91us/step - loss: 30.2962 - mae: 3.5489 - val_loss: 36.5105 - val_mae: 4.1331\n",
      "Epoch 85/100\n",
      "323/323 [==============================] - 0s 96us/step - loss: 29.8949 - mae: 3.5281 - val_loss: 35.8333 - val_mae: 4.1004\n",
      "Epoch 86/100\n",
      "323/323 [==============================] - 0s 91us/step - loss: 29.4843 - mae: 3.5034 - val_loss: 35.0458 - val_mae: 4.0585\n",
      "Epoch 87/100\n",
      "323/323 [==============================] - 0s 99us/step - loss: 28.9804 - mae: 3.4797 - val_loss: 34.2786 - val_mae: 4.0214\n",
      "Epoch 88/100\n",
      "323/323 [==============================] - 0s 92us/step - loss: 28.4840 - mae: 3.4383 - val_loss: 33.6976 - val_mae: 3.9895\n",
      "Epoch 89/100\n",
      "323/323 [==============================] - 0s 89us/step - loss: 27.9059 - mae: 3.3969 - val_loss: 32.8881 - val_mae: 3.9522\n",
      "Epoch 90/100\n",
      "323/323 [==============================] - 0s 94us/step - loss: 27.4707 - mae: 3.3866 - val_loss: 32.1708 - val_mae: 3.9214\n",
      "Epoch 91/100\n",
      "323/323 [==============================] - 0s 99us/step - loss: 26.9377 - mae: 3.3763 - val_loss: 31.5846 - val_mae: 3.8917\n",
      "Epoch 92/100\n",
      "323/323 [==============================] - 0s 91us/step - loss: 26.5494 - mae: 3.3514 - val_loss: 31.2611 - val_mae: 3.8805\n",
      "Epoch 93/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 26.1328 - mae: 3.3100 - val_loss: 30.5177 - val_mae: 3.8403\n",
      "Epoch 94/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 25.7594 - mae: 3.3005 - val_loss: 29.9192 - val_mae: 3.8001\n",
      "Epoch 95/100\n",
      "323/323 [==============================] - 0s 96us/step - loss: 25.3922 - mae: 3.2864 - val_loss: 29.4279 - val_mae: 3.7731\n",
      "Epoch 96/100\n",
      "323/323 [==============================] - 0s 96us/step - loss: 25.0672 - mae: 3.2644 - val_loss: 28.8142 - val_mae: 3.7391\n",
      "Epoch 97/100\n",
      "323/323 [==============================] - 0s 90us/step - loss: 24.6150 - mae: 3.2343 - val_loss: 28.1219 - val_mae: 3.7102\n",
      "Epoch 98/100\n",
      "323/323 [==============================] - 0s 96us/step - loss: 24.2460 - mae: 3.2142 - val_loss: 27.7556 - val_mae: 3.6813\n",
      "Epoch 99/100\n",
      "323/323 [==============================] - 0s 94us/step - loss: 23.9277 - mae: 3.1953 - val_loss: 27.2814 - val_mae: 3.6472\n",
      "Epoch 100/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 23.6618 - mae: 3.1690 - val_loss: 26.6254 - val_mae: 3.6207\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "history = model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 63us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[27.78502991620232, 4.09093713760376]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test)\n",
    "# output values represent the loss(MSE) and the metrics(MAE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13.933856]\n",
      " [17.02238 ]]\n"
     ]
    }
   ],
   "source": [
    "to_predict = X_test_scaled[:2]\n",
    "predictions = model.predict(to_predict)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.2 18.8]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
